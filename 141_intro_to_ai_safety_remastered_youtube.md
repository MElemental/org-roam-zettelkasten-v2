
# Table of Contents

1.  [AI Safety](#org42c9c99)
2.  [Agents](#orgff0e3ab)
    1.  [Thermostat](#org44fbcc4)
    2.  [Chess AI](#org5041447)
3.  [Generality](#orgb6bab21)
4.  [Misalignment](#orgc017b65)
5.  [Stuart Russel](#org2ad6fba)
6.  [&ldquo;Just Turn it off&rdquo;](#org18789a7)
    1.  [References](#orgcd3ca47)
7.  [Instrumental vs Terminal Goals](#orge59896e)
    1.  [Convergent Instrumental Goals](#org9b11d81)



<a id="org42c9c99"></a>

# AI Safety

What is the most important problem in AI Safety.
We will, sooner or later build an artificial general intelligence.


<a id="orgff0e3ab"></a>

# Agents


<a id="org44fbcc4"></a>

## Thermostat

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">goals</td>
<td class="org-left">actions</td>
</tr>


<tr>
<td class="org-left">keep temperature at some degree</td>
<td class="org-left">turn on and off</td>
</tr>
</tbody>
</table>


<a id="org5041447"></a>

## Chess AI

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">goals</td>
<td class="org-left">actions</td>
</tr>


<tr>
<td class="org-left">win chess</td>
<td class="org-left">move pieces</td>
</tr>
</tbody>
</table>


<a id="orgb6bab21"></a>

# Generality

The ability to behave in a wide range of domains
Humans are currently the most general intelligence


<a id="orgc017b65"></a>

# Misalignment

Coast Runner
Picking objectives are hard
Tetris Pause Screen


<a id="org2ad6fba"></a>

# Stuart Russel

&ldquo;A system that is optimizing a function of *n* variables where the objective depends on a subset of size *k<n*, will often set the remaining unconstrained variables to extreme values. If one of those unconstrained variables is something we care about, the solution found may be *highly undesirable*&rdquo;


<a id="org18789a7"></a>

# &ldquo;Just Turn it off&rdquo;

An GAI will not let you turn it off, it will fight or deceive


<a id="orgcd3ca47"></a>

## References


[AI &ldquo;Stop Button&rdquo; Problem - Computerphile - YouTube](151_ai_stop_button_problem_computerphile_youtube.md)


<a id="orge59896e"></a>

# Instrumental vs Terminal Goals


<a id="org9b11d81"></a>

## Convergent Instrumental Goals

Self Preservation
Goal Preservation
Resource Acquisition
Self Improvement
Artificial General Intelligence is dangerous by default.

